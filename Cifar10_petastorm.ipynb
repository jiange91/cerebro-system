{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3d83f79",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T00:21:33.258916Z",
     "start_time": "2021-12-08T00:21:29.324065Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEREBRO => Time: 2021-12-07 17:21:33, Running 6 Workers\n"
     ]
    }
   ],
   "source": [
    "from cerebro.backend import SparkBackend\n",
    "from cerebro.keras import SparkEstimator\n",
    "\n",
    "# datas storage for intermediate data and model artifacts.\n",
    "from cerebro.storage import LocalStore, HDFSStore\n",
    "\n",
    "# Model selection/AutoML methods.\n",
    "from cerebro.tune import GridSearch, RandomSearch, TPESearch\n",
    "\n",
    "# Utility functions for specifying the search space.\n",
    "from cerebro.tune import hp_choice, hp_uniform, hp_quniform, hp_loguniform, hp_qloguniform\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "os.environ[\"PYSPARK_PYTHON\"] = '/usr/bin/python3.6'\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = '/usr/bin/python3.6'\n",
    "\n",
    "from pyspark import SparkConf\n",
    "\n",
    "conf = SparkConf().setAppName('cluster') \\\n",
    "    .setMaster('spark://10.10.1.1:7077') \\\n",
    "    .set('spark.task.cpus', '16') \\\n",
    "    .set('spark.executor.memory', '124g')\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "spark.sparkContext.addPyFile(\"cerebro.zip\")\n",
    "\n",
    "work_dir = '/var/nfs/'\n",
    "backend = SparkBackend(spark_context=spark.sparkContext, num_workers=6)\n",
    "store = LocalStore(prefix_path=work_dir + 'test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6bc31c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-08T00:22:34.241666Z",
     "start_time": "2021-12-08T00:21:57.155314Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import datasets\n",
    "from petastorm.codecs import CompressedImageCodec, \\\n",
    "        NdarrayCodec, ScalarCodec\n",
    "from petastorm.etl.dataset_metadata import materialize_dataset\n",
    "from petastorm.unischema import Unischema,\\\n",
    "        UnischemaField, dict_to_spark_row\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "MySchema = Unischema('MySchema', [\n",
    "    UnischemaField('image', np.uint8,\n",
    "                   (32,32,3), NdarrayCodec(), False),\n",
    "    UnischemaField('label', np.float32,\n",
    "                   (10,), NdarrayCodec(), False),\n",
    "])\n",
    "(data, labels), _ = datasets.cifar10.load_data()\n",
    "labels = keras.utils.to_categorical(labels, 10)\n",
    "\n",
    "data_train, data_val, labels_train, labels_val = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "num_procs = 4 # set the number of parallel processes\n",
    "sc = spark.sparkContext\n",
    "num_samples_train = len(labels_train)\n",
    "num_samples_val = len(labels_val)\n",
    "output_url_train = 'file:///var/nfs/test/intermediate_train_data/'\n",
    "output_url_val = 'file:///var/nfs/test/intermediate_val_data/'\n",
    "rowgroup_size_mb = 8\n",
    "def row_generator_train(i):\n",
    "    return {\n",
    "        'image': data_train[i],\n",
    "        'label': labels_train[i],\n",
    "    }\n",
    "def row_generator_val(i):\n",
    "    return {\n",
    "        'image': data_val[i],\n",
    "        'label': labels_val[i],\n",
    "    }\n",
    "# Wrap dataset materialization portion.\n",
    "# Will take care of setting up spark environment variables as\n",
    "# well as save petastorm specific metadata\n",
    "with materialize_dataset(spark, output_url_train,\n",
    "                         MySchema, rowgroup_size_mb):\n",
    "    rows_rdd = sc.parallelize(range(num_samples_train)) \\\n",
    "        .map(row_generator_train) \\\n",
    "        .map(lambda x: dict_to_spark_row(MySchema, x))\n",
    "    spark.createDataFrame(rows_rdd, \n",
    "                          MySchema.as_spark_schema()) \\\n",
    "        .write \\\n",
    "        .mode('overwrite') \\\n",
    "        .parquet(output_url_train)\n",
    "\n",
    "with materialize_dataset(spark, output_url_val,\n",
    "                         MySchema, rowgroup_size_mb):\n",
    "    rows_rdd = sc.parallelize(range(num_samples_val)) \\\n",
    "        .map(row_generator_val) \\\n",
    "        .map(lambda x: dict_to_spark_row(MySchema, x))\n",
    "    spark.createDataFrame(rows_rdd, \n",
    "                          MySchema.as_spark_schema()) \\\n",
    "        .write \\\n",
    "        .mode('overwrite') \\\n",
    "        .parquet(output_url_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a552bb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T23:52:15.994314Z",
     "start_time": "2021-12-07T23:52:15.714001Z"
    }
   },
   "outputs": [],
   "source": [
    "(data, labels), _ = datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d1e00d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T23:52:21.949323Z",
     "start_time": "2021-12-07T23:52:21.942173Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "64c863c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T23:52:27.435336Z",
     "start_time": "2021-12-07T23:52:27.432853Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = keras.utils.to_categorical(labels, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c441ef6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T23:52:58.040178Z",
     "start_time": "2021-12-07T23:52:58.031761Z"
    }
   },
   "outputs": [],
   "source": [
    "with open ('/var/nfs/cifar10/prep_np/prep.npy', 'wb') as f:\n",
    "    np.save(f, data[:100])\n",
    "    np.save(f, labels[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "607636c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T23:52:59.506921Z",
     "start_time": "2021-12-07T23:52:59.503931Z"
    }
   },
   "outputs": [],
   "source": [
    "with open ('/var/nfs/cifar10/prep_np/prep.npy', 'rb') as f:\n",
    "    x = np.load(f)\n",
    "    y = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "232a6f61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T23:53:02.790844Z",
     "start_time": "2021-12-07T23:53:02.788444Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 32, 32, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9658a2c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-07T23:53:09.891408Z",
     "start_time": "2021-12-07T23:53:09.888746Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d02c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
