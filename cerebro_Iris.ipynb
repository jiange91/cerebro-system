{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ce6a85e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/11/22 06:45:45 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "21/11/22 06:45:45 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "21/11/22 06:45:45 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEREBRO => Time: 2021-11-22 06:45:46, Running 1 Workers\n",
      "CEREBRO => Time: 2021-11-22 06:45:49, Preparing Data\n",
      "CEREBRO => Time: 2021-11-22 06:45:50, Num Partitions: 1\n",
      "CEREBRO => Time: 2021-11-22 06:45:50, Writing DataFrames\n",
      "CEREBRO => Time: 2021-11-22 06:45:50, Train Data Path: file:///Users/zijian/Desktop/ucsd/cse234/project/cerebro-system/experiments/intermediate_train_data\n",
      "CEREBRO => Time: 2021-11-22 06:45:50, Val Data Path: file:///Users/zijian/Desktop/ucsd/cse234/project/cerebro-system/experiments/intermediate_val_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEREBRO => Time: 2021-11-22 06:45:51, Train Partitions: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEREBRO => Time: 2021-11-22 06:45:55, Val Partitions: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEREBRO => Time: 2021-11-22 06:45:58, Train Rows: 93\n",
      "CEREBRO => Time: 2021-11-22 06:45:58, Val Rows: 19\n",
      "CEREBRO => Time: 2021-11-22 06:45:58, Initializing Workers\n",
      "CEREBRO => Time: 2021-11-22 06:45:58, Initializing Data Loaders\n",
      "CEREBRO => Time: 2021-11-22 06:45:58, Launching Model Selection Workload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 06:45:58.920273: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-11-22 06:45:58.920444: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[Stage 10:>                                                         (0 + 1) / 1]2021-11-22 06:45:59.095196: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-11-22 06:45:59.181146: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-22 06:45:59.185540: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:196] None of the MLIR optimization passes are enabled (registered 0 passes)\n",
      "WARNING:tensorflow:From /Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:2561: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_types is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:From /Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:2561: calling DatasetV2.from_generator (from tensorflow.python.data.ops.dataset_ops) with output_shapes is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use output_signature instead\n",
      "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
      "2021-11-22 06:45:59.898884: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "Train on 6 steps\n",
      "6/6 [==============================] - 0s 2ms/step - batch: 2.5000 - size: 1.0000 - loss: 3.5598 - accuracy: 0.1562    \n",
      "CEREBRO => Time: 2021-11-22 06:46:00, Model: model_0_1637592359, Mode: TRAIN, Initialization Time: 0.7288448810577393, Training Time: 0.37389516830444336, Finalization Time: 0.1153421401977539\n",
      "/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:2325: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n",
      "2021-11-22 06:46:03.974251: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_2 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_2 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:46:03.974623: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_2 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_2 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:46:03, Model: model_0_1637592359, Mode: VALID, Initialization Time: 0.6420040130615234, Training Time: 0.14294099807739258, Finalization Time: 0.07294583320617676\n",
      "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
      "Train on 6 steps\n",
      "Epoch 2/2\n",
      "6/6 [==============================] - 0s 4ms/step - batch: 2.5000 - size: 1.0000 - loss: 1.1557 - accuracy: 0.3333    \n",
      "2021-11-22 06:46:08.063336: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_5 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_5 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:46:08.063714: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_5 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_5 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:46:08, Model: model_0_1637592359, Mode: TRAIN, Initialization Time: 0.5513110160827637, Training Time: 0.22402501106262207, Finalization Time: 0.11908197402954102\n",
      "2021-11-22 06:46:11.871241: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_8 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_8 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:46:11.871618: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_8 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_8 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:46:11, Model: model_0_1637592359, Mode: VALID, Initialization Time: 0.49091482162475586, Training Time: 0.10982513427734375, Finalization Time: 0.06993699073791504\n",
      "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
      "Train on 6 steps\n",
      "Epoch 3/3\n",
      "6/6 [==============================] - 0s 5ms/step - batch: 2.5000 - size: 1.0000 - loss: 0.8184 - accuracy: 0.5729\n",
      "2021-11-22 06:46:16.319689: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_11 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_11 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:46:16.320063: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_11 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_11 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:46:16, Model: model_0_1637592359, Mode: TRAIN, Initialization Time: 0.5641298294067383, Training Time: 0.3716580867767334, Finalization Time: 0.13255810737609863\n",
      "2021-11-22 06:46:19.975020: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_14 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_14 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:46:19.975394: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_14 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_14 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:46:19, Model: model_0_1637592359, Mode: VALID, Initialization Time: 0.5041606426239014, Training Time: 0.11203503608703613, Finalization Time: 0.07352495193481445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
      "Train on 6 steps\n",
      "Epoch 4/4\n",
      "6/6 [==============================] - 0s 5ms/step - batch: 2.5000 - size: 1.0000 - loss: 0.5561 - accuracy: 0.6562\n",
      "2021-11-22 06:46:24.213675: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_17 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_17 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:46:24.214068: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_17 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_17 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:46:24, Model: model_0_1637592359, Mode: TRAIN, Initialization Time: 0.4973418712615967, Training Time: 0.26290202140808105, Finalization Time: 0.11854982376098633\n",
      "2021-11-22 06:46:28.058669: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_20 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_20 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:46:28.059061: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_20 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_20 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:46:28, Model: model_0_1637592359, Mode: VALID, Initialization Time: 0.5012669563293457, Training Time: 0.11745405197143555, Finalization Time: 0.0730741024017334\n",
      "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
      "Train on 6 steps\n",
      "Epoch 5/5\n",
      "6/6 [==============================] - 0s 4ms/step - batch: 2.5000 - size: 1.0000 - loss: 0.5155 - accuracy: 0.6562    \n",
      "2021-11-22 06:46:32.328597: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_23 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_23 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:46:32.328972: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_23 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_23 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:46:32, Model: model_0_1637592359, Mode: TRAIN, Initialization Time: 0.5586521625518799, Training Time: 0.22745609283447266, Finalization Time: 0.13213586807250977\n",
      "2021-11-22 06:46:36.106607: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_26 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_26 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:46:36.106979: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_26 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_26 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:46:36, Model: model_0_1637592359, Mode: VALID, Initialization Time: 0.48210787773132324, Training Time: 0.10887002944946289, Finalization Time: 0.07019591331481934\n",
      "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
      "Train on 6 steps\n",
      "Epoch 6/6\n",
      "6/6 [==============================] - 0s 4ms/step - batch: 2.5000 - size: 1.0000 - loss: 0.4821 - accuracy: 0.6771\n",
      "2021-11-22 06:46:40.311149: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_29 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_29 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:46:40.311564: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_29 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_29 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:46:40, Model: model_0_1637592359, Mode: TRAIN, Initialization Time: 0.48358893394470215, Training Time: 0.22230911254882812, Finalization Time: 0.1142721176147461\n",
      "2021-11-22 06:46:44.227292: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_32 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_32 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:46:44.227595: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_32 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_32 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:46:44, Model: model_0_1637592359, Mode: VALID, Initialization Time: 0.5167069435119629, Training Time: 0.11199212074279785, Finalization Time: 0.06540799140930176\n",
      "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
      "Train on 6 steps\n",
      "Epoch 7/7\n",
      "6/6 [==============================] - 0s 4ms/step - batch: 2.5000 - size: 1.0000 - loss: 0.3556 - accuracy: 0.8646\n",
      "2021-11-22 06:46:48.513585: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_35 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_35 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:46:48.513979: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_35 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_35 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:46:48, Model: model_0_1637592359, Mode: TRAIN, Initialization Time: 0.57558274269104, Training Time: 0.23176980018615723, Finalization Time: 0.130357027053833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 06:46:52.356789: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_38 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_38 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:46:52.357190: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_38 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_38 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:46:52, Model: model_0_1637592359, Mode: VALID, Initialization Time: 0.5285928249359131, Training Time: 0.13821101188659668, Finalization Time: 0.07413816452026367\n",
      "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
      "Train on 6 steps\n",
      "Epoch 8/8\n",
      "6/6 [==============================] - 0s 4ms/step - batch: 2.5000 - size: 1.0000 - loss: 0.4118 - accuracy: 0.8021\n",
      "2021-11-22 06:46:56.611382: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_41 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_41 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:46:56.611759: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_41 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_41 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:46:56, Model: model_0_1637592359, Mode: TRAIN, Initialization Time: 0.5825998783111572, Training Time: 0.24144315719604492, Finalization Time: 0.1210329532623291\n",
      "[Stage 10:>                                                         (0 + 1) / 1]2021-11-22 06:47:00.428137: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_44 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_44 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:47:00.428553: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_44 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_44 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:47:00, Model: model_0_1637592359, Mode: VALID, Initialization Time: 0.5347442626953125, Training Time: 0.11666464805603027, Finalization Time: 0.07603812217712402\n",
      "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
      "Train on 6 steps\n",
      "Epoch 9/9\n",
      "6/6 [==============================] - 0s 4ms/step - batch: 2.5000 - size: 1.0000 - loss: 0.2594 - accuracy: 0.9375\n",
      "2021-11-22 06:47:04.584990: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_47 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_47 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:47:04.585409: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_47 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_47 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:47:04, Model: model_0_1637592359, Mode: TRAIN, Initialization Time: 0.4911689758300781, Training Time: 0.22939324378967285, Finalization Time: 0.11785316467285156\n",
      "2021-11-22 06:47:08.428746: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_50 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_50 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:47:08.429022: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_50 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_50 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:47:08, Model: model_0_1637592359, Mode: VALID, Initialization Time: 0.4779829978942871, Training Time: 0.10840010643005371, Finalization Time: 0.05940890312194824\n",
      "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
      "Train on 6 steps\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 3ms/step - batch: 2.5000 - size: 1.0000 - loss: 0.3829 - accuracy: 0.8125\n",
      "2021-11-22 06:47:12.686984: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_53 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_53 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:47:12.687412: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_53 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_53 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:47:12, Model: model_0_1637592359, Mode: TRAIN, Initialization Time: 0.4939258098602295, Training Time: 0.23638200759887695, Finalization Time: 0.13113999366760254\n",
      "2021-11-22 06:47:16.548377: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_56 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_56 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:47:16.548796: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_56 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_56 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:47:16, Model: model_0_1637592359, Mode: VALID, Initialization Time: 0.4980952739715576, Training Time: 0.11625289916992188, Finalization Time: 0.07703614234924316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
      "Train on 6 steps\n",
      "Epoch 11/11\n",
      "6/6 [==============================] - 0s 3ms/step - batch: 2.5000 - size: 1.0000 - loss: 0.1641 - accuracy: 0.9479\n",
      "2021-11-22 06:47:20.781459: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_59 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_59 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:47:20.781842: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_59 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_59 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:47:20, Model: model_0_1637592359, Mode: TRAIN, Initialization Time: 0.4887509346008301, Training Time: 0.271359920501709, Finalization Time: 0.11484909057617188\n",
      "2021-11-22 06:47:24.741375: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_62 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_62 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:47:24.741838: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_62 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_62 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:47:24, Model: model_0_1637592359, Mode: VALID, Initialization Time: 0.6113910675048828, Training Time: 0.10926628112792969, Finalization Time: 0.07544803619384766\n",
      "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
      "Train on 6 steps\n",
      "Epoch 12/12\n",
      "6/6 [==============================] - 0s 3ms/step - batch: 2.5000 - size: 1.0000 - loss: 0.2705 - accuracy: 0.8958\n",
      "2021-11-22 06:47:28.856779: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_65 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_65 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:47:28.857198: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_65 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_65 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:47:28, Model: model_0_1637592359, Mode: TRAIN, Initialization Time: 0.5168423652648926, Training Time: 0.22688579559326172, Finalization Time: 0.11753487586975098\n",
      "2021-11-22 06:47:32.715499: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_68 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_68 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:47:32.715891: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_68 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_68 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:47:32, Model: model_0_1637592359, Mode: VALID, Initialization Time: 0.5030338764190674, Training Time: 0.10926508903503418, Finalization Time: 0.07115292549133301\n",
      "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
      "Train on 6 steps\n",
      "Epoch 13/13\n",
      "6/6 [==============================] - 0s 3ms/step - batch: 2.5000 - size: 1.0000 - loss: 0.1098 - accuracy: 0.9583\n",
      "2021-11-22 06:47:36.963042: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_71 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_71 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:47:36.963424: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_71 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_71 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:47:36, Model: model_0_1637592359, Mode: TRAIN, Initialization Time: 0.5277299880981445, Training Time: 0.23519301414489746, Finalization Time: 0.12142086029052734\n",
      "2021-11-22 06:47:40.816890: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_74 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_74 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:47:40.817280: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_74 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_74 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:47:40, Model: model_0_1637592359, Mode: VALID, Initialization Time: 0.5170450210571289, Training Time: 0.11063194274902344, Finalization Time: 0.07498025894165039\n",
      "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
      "Train on 6 steps\n",
      "Epoch 14/14\n",
      "6/6 [==============================] - 0s 4ms/step - batch: 2.5000 - size: 1.0000 - loss: 0.2837 - accuracy: 0.8750\n",
      "2021-11-22 06:47:45.125597: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_77 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_77 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:47:45.125994: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_77 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_77 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:47:45, Model: model_0_1637592359, Mode: TRAIN, Initialization Time: 0.5691182613372803, Training Time: 0.251478910446167, Finalization Time: 0.14499402046203613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 06:47:48.876042: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_80 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_80 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:47:48.876440: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_80 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_80 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:47:48, Model: model_0_1637592359, Mode: VALID, Initialization Time: 0.490185022354126, Training Time: 0.12152886390686035, Finalization Time: 0.07117199897766113\n",
      "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
      "Train on 6 steps\n",
      "Epoch 15/15\n",
      "6/6 [==============================] - 0s 4ms/step - batch: 2.5000 - size: 1.0000 - loss: 0.1265 - accuracy: 0.9375\n",
      "2021-11-22 06:47:53.118446: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_83 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_83 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:47:53.118824: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_83 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_83 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:47:53, Model: model_0_1637592359, Mode: TRAIN, Initialization Time: 0.5145699977874756, Training Time: 0.22986316680908203, Finalization Time: 0.1304328441619873\n",
      "2021-11-22 06:47:56.949168: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_86 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_86 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:47:56.949641: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_86 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_86 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:47:56, Model: model_0_1637592359, Mode: VALID, Initialization Time: 0.49488377571105957, Training Time: 0.10749602317810059, Finalization Time: 0.07088422775268555\n",
      "[Stage 10:>                                                         (0 + 1) / 1]WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
      "Train on 6 steps\n",
      "Epoch 16/16\n",
      "6/6 [==============================] - 0s 3ms/step - batch: 2.5000 - size: 1.0000 - loss: 0.4466 - accuracy: 0.8438\n",
      "2021-11-22 06:48:01.150919: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_89 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_89 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:48:01.151213: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_89 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_89 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:48:01, Model: model_0_1637592359, Mode: TRAIN, Initialization Time: 0.4888272285461426, Training Time: 0.2253711223602295, Finalization Time: 0.10809803009033203\n",
      "2021-11-22 06:48:05.076398: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_92 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_92 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:48:05.076890: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_92 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_92 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:48:05, Model: model_0_1637592359, Mode: VALID, Initialization Time: 0.5234112739562988, Training Time: 0.11702084541320801, Finalization Time: 0.07273507118225098\n",
      "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
      "Train on 6 steps\n",
      "Epoch 17/17\n",
      "6/6 [==============================] - 0s 4ms/step - batch: 2.5000 - size: 1.0000 - loss: 1.1701 - accuracy: 0.5729\n",
      "2021-11-22 06:48:09.612890: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_95 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_95 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:48:09.613274: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_95 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_95 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:48:09, Model: model_0_1637592359, Mode: TRAIN, Initialization Time: 0.7441239356994629, Training Time: 0.3236558437347412, Finalization Time: 0.13759303092956543\n",
      "2021-11-22 06:48:13.162588: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_98 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_98 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:48:13.162964: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_98 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_98 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:48:13, Model: model_0_1637592359, Mode: VALID, Initialization Time: 0.521569013595581, Training Time: 0.12651801109313965, Finalization Time: 0.07457709312438965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
      "Train on 6 steps\n",
      "Epoch 18/18\n",
      "6/6 [==============================] - 0s 5ms/step - batch: 2.5000 - size: 1.0000 - loss: 0.3829 - accuracy: 0.6979\n",
      "2021-11-22 06:48:17.618872: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_101 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_101 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:48:17.619261: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_101 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_101 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:48:17, Model: model_0_1637592359, Mode: TRAIN, Initialization Time: 0.7135217189788818, Training Time: 0.2778208255767822, Finalization Time: 0.13838815689086914\n",
      "2021-11-22 06:48:21.201055: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_104 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_104 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:48:21.201442: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_104 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_104 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:48:21, Model: model_0_1637592359, Mode: VALID, Initialization Time: 0.4950380325317383, Training Time: 0.11116909980773926, Finalization Time: 0.07242989540100098\n",
      "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
      "Train on 6 steps\n",
      "Epoch 19/19\n",
      "6/6 [==============================] - 0s 4ms/step - batch: 2.5000 - size: 1.0000 - loss: 0.3963 - accuracy: 0.8229\n",
      "2021-11-22 06:48:25.425924: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_107 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_107 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:48:25.426206: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_107 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_107 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:48:25, Model: model_0_1637592359, Mode: TRAIN, Initialization Time: 0.50187087059021, Training Time: 0.23435306549072266, Finalization Time: 0.11759710311889648\n",
      "2021-11-22 06:48:29.266346: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_110 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_110 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:48:29.266812: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_110 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_110 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:48:29, Model: model_0_1637592359, Mode: VALID, Initialization Time: 0.477078914642334, Training Time: 0.11156606674194336, Finalization Time: 0.07341504096984863\n",
      "WARNING:tensorflow:Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n",
      "Train on 6 steps\n",
      "Epoch 20/20\n",
      "6/6 [==============================] - 0s 4ms/step - batch: 2.5000 - size: 1.0000 - loss: 0.4161 - accuracy: 0.8021\n",
      "2021-11-22 06:48:33.493678: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_113 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_113 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:48:33.494064: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_113 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_113 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:48:33, Model: model_0_1637592359, Mode: TRAIN, Initialization Time: 0.4964909553527832, Training Time: 0.2255260944366455, Finalization Time: 0.12106704711914062\n",
      "2021-11-22 06:48:37.341248: W tensorflow/core/framework/op_kernel.cc:1751] Invalid argument: ValueError: callback pyfunc_116 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_116 is not found\n",
      "\n",
      "\n",
      "2021-11-22 06:48:37.341642: W tensorflow/core/kernels/data/generator_dataset_op.cc:107] Error occurred when finalizing GeneratorDataset iterator: Invalid argument: ValueError: callback pyfunc_116 is not found\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/Users/zijian/.pyenv/versions/nocerebro/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 238, in __call__\n",
      "    raise ValueError(\"callback %s is not found\" % token)\n",
      "\n",
      "ValueError: callback pyfunc_116 is not found\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "CEREBRO => Time: 2021-11-22 06:48:37, Model: model_0_1637592359, Mode: VALID, Initialization Time: 0.4738309383392334, Training Time: 0.1110389232635498, Finalization Time: 0.07212996482849121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEREBRO => Time: 2021-11-22 06:48:40, Terminating Workers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 11:>                                                         (0 + 1) / 1]2021-11-22 06:48:44.577813: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-11-22 06:48:44.578291: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-22 06:48:44.721075: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "[Stage 12:>                                                         (0 + 1) / 1]2021-11-22 06:48:47.355123: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-11-22 06:48:47.355629: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-22 06:48:47.469139: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|Species|     label_predicted|\n",
      "+-------+--------------------+\n",
      "|      0|[0.99996840953826...|\n",
      "|      0|[0.99999892711639...|\n",
      "|      2|[0.00283555034548...|\n",
      "|      0|[0.99995791912078...|\n",
      "|      0|[0.99995791912078...|\n",
      "|      0|[0.99995791912078...|\n",
      "|      0|[0.99990284442901...|\n",
      "|      0|[0.99999284744262...|\n",
      "|      0|[0.99998354911804...|\n",
      "|      0|[0.99995231628417...|\n",
      "+-------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from cerebro.backend import SparkBackend\n",
    "from cerebro.keras import SparkEstimator\n",
    "\n",
    "# datas storage for intermediate data and model artifacts.\n",
    "from cerebro.storage import LocalStore, HDFSStore\n",
    "\n",
    "# Model selection/AutoML methods.\n",
    "from cerebro.tune import GridSearch, RandomSearch, TPESearch\n",
    "\n",
    "# Utility functions for specifying the search space.\n",
    "from cerebro.tune import hp_choice, hp_uniform, hp_quniform, hp_loguniform, hp_qloguniform\n",
    "\n",
    "import tensorflow as tf\n",
    "# tf.config.run_functions_eagerly(True)\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Cerebro Iris\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "...\n",
    "\n",
    "backend = SparkBackend(spark_context=spark.sparkContext, num_workers=1)\n",
    "store = LocalStore(prefix_path='/Users/zijian/Desktop/ucsd/cse234/project/cerebro-system/experiments')\n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "\n",
    "df = spark.read.csv(\"/Users/zijian/Desktop/ucsd/cse234/project/cerebro-system/Iris_clean.csv\", header=True, inferSchema=True)\n",
    "\n",
    "encoder = OneHotEncoderEstimator(dropLast=False)\n",
    "encoder.setInputCols([\"Species\"])\n",
    "encoder.setOutputCols([\"Species_OHE\"])\n",
    "\n",
    "encoder_model = encoder.fit(df)\n",
    "encoded = encoder_model.transform(df)\n",
    "\n",
    "feature_columns=['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n",
    "label_columns=['Species_OHE']\n",
    "\n",
    "# Initialize input DataFrames.\n",
    "# You can download sample dataset from https://apache.googlesource.com/spark/+/master/data/mllib/sample_libsvm_data.txt\n",
    "\n",
    "train_df, test_df = encoded.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Define estimator generating function.\n",
    "# Input: Dictionary containing parameter values\n",
    "# Output: SparkEstimator\n",
    "def estimator_gen_fn(params):\n",
    "#     inputs = [tf.keras.Input(shape=(1,)) for col in feature_columns]\n",
    "#     embeddings1 = [tf.keras.layers.Dense(16, activation=tf.nn.relu)(input) for input in inputs]\n",
    "#     embeddings2 = [tf.keras.layers.Dense(32, activation=tf.nn.relu)(input) for input in embeddings1]\n",
    "#     combined = tf.keras.layers.Concatenate()(embeddings2)\n",
    "#     output = tf.keras.layers.Dense(3, activation=tf.nn.softmax)(combined)\n",
    "#     model = tf.keras.Model(inputs, output)\n",
    "\n",
    "    inputs = [tf.keras.Input(shape=(1,)) for col in feature_columns]\n",
    "    concat = tf.keras.layers.Concatenate()(inputs)\n",
    "    output1 = tf.keras.layers.Dense(128, activation=tf.nn.relu)(concat)\n",
    "    output2 = tf.keras.layers.Dense(1024, activation=tf.nn.relu)(output1)\n",
    "    output = tf.keras.layers.Dense(3, activation=tf.nn.softmax)(output2)\n",
    "    model = tf.keras.Model(inputs, output)\n",
    "\n",
    "#     inputs = tf.keras.Input(shape=(4,))\n",
    "#     output1 = tf.keras.layers.Dense(16, activation=tf.nn.relu)(inputs)\n",
    "#     output2 = tf.keras.layers.Dense(32, activation=tf.nn.relu)(output1)\n",
    "#     output = tf.keras.layers.Dense(3, activation=tf.nn.softmax)(output2)\n",
    "#     model = tf.keras.Model(inputs, output)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=params['lr'])\n",
    "    loss = 'categorical_crossentropy'\n",
    "\n",
    "    estimator = SparkEstimator(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy'],\n",
    "        batch_size=params['batch_size'])\n",
    "\n",
    "    return estimator\n",
    "\n",
    "# Define dictionary containing the parameter search space.\n",
    "search_space = {\n",
    "    'lr': hp_choice([0.01]),\n",
    "    'batch_size': hp_choice([16])\n",
    "}\n",
    "\n",
    "# Instantiate TPE (Tree of Parzan Estimators a.k.a., HyperOpt) model selection object.\n",
    "model_selection = RandomSearch(\n",
    "    backend=backend, \n",
    "    store=store, \n",
    "    estimator_gen_fn=estimator_gen_fn, \n",
    "    search_space=search_space,\n",
    "    num_models=1, \n",
    "    num_epochs=20, \n",
    "    validation=0.2, \n",
    "    evaluation_metric='accuracy',\n",
    "    feature_columns=feature_columns,\n",
    "    label_columns=label_columns\n",
    ")\n",
    "\n",
    "# Perform model selection. Returns best model.\n",
    "model = model_selection.fit(train_df)\n",
    "\n",
    "# Inspect best model training history.\n",
    "model_history = model.get_history()\n",
    "\n",
    "# # Perform inference using the best model and Spark DataFrame.\n",
    "output_df = model.set_output_columns(['label_predicted']).transform(test_df)\n",
    "output_df.select('Species', 'label_predicted').show(n=10)\n",
    "\n",
    "# # Access all models.\n",
    "# all_models = model.get_all_models()\n",
    "# all_model_training_history = model.get_all_model_history()\n",
    "\n",
    "# # Convert the best model to Keras and perform inference using numpy data.\n",
    "# keras_model = model.keras()\n",
    "# pred = keras_model.predict([np.ones([1, 692], dtype=np.float32)])\n",
    "# # Save the keras checkpoint file.\n",
    "# keras_model.save(ckpt_path)\n",
    "\n",
    "# # Convert all the model to Keras.\n",
    "# all_models_keras = [m.keras() for m in all_models]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32047688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model_0_1637592359': {'train_loss': [3.5598298708597818,\n",
       "   1.1557079950968425,\n",
       "   0.8183964689572653,\n",
       "   0.55611935009559,\n",
       "   0.5155076410155743,\n",
       "   0.48213007384523127,\n",
       "   0.35561879443654715,\n",
       "   0.4118161859223619,\n",
       "   0.25939790980676963,\n",
       "   0.38293483707820997,\n",
       "   0.1640534773662997,\n",
       "   0.2704889229886855,\n",
       "   0.1097771948358665,\n",
       "   0.28366075836432475,\n",
       "   0.12651007315920046,\n",
       "   0.44658533505329007,\n",
       "   1.1701089578370254,\n",
       "   0.3829073728993535,\n",
       "   0.39633384958142415,\n",
       "   0.41608361599598237],\n",
       "  'train_accuracy': [0.15625,\n",
       "   0.3333333432674408,\n",
       "   0.5729166865348816,\n",
       "   0.65625,\n",
       "   0.65625,\n",
       "   0.6770833134651184,\n",
       "   0.8645833134651184,\n",
       "   0.8020833134651184,\n",
       "   0.9375,\n",
       "   0.8125,\n",
       "   0.9479166865348816,\n",
       "   0.8958333134651184,\n",
       "   0.9583333134651184,\n",
       "   0.875,\n",
       "   0.9375,\n",
       "   0.84375,\n",
       "   0.5729166865348816,\n",
       "   0.6979166865348816,\n",
       "   0.8229166865348816,\n",
       "   0.8020833134651184],\n",
       "  'val_loss': [1.0147390365600586,\n",
       "   0.8646733462810516,\n",
       "   0.522622138261795,\n",
       "   0.5134254693984985,\n",
       "   0.4826420843601227,\n",
       "   0.4036994129419327,\n",
       "   0.34424158930778503,\n",
       "   0.26431381702423096,\n",
       "   0.19931229948997498,\n",
       "   0.20401012897491455,\n",
       "   0.14573021233081818,\n",
       "   0.1460253745317459,\n",
       "   0.1285715252161026,\n",
       "   0.17894812673330307,\n",
       "   0.49077482521533966,\n",
       "   1.0118185877799988,\n",
       "   0.5339368581771851,\n",
       "   0.4586724787950516,\n",
       "   0.5584477186203003,\n",
       "   0.35050706565380096],\n",
       "  'val_accuracy': [0.4375,\n",
       "   0.5,\n",
       "   0.75,\n",
       "   0.65625,\n",
       "   0.75,\n",
       "   0.8125,\n",
       "   0.9375,\n",
       "   0.9375,\n",
       "   1.0,\n",
       "   0.96875,\n",
       "   0.9375,\n",
       "   0.9375,\n",
       "   0.9375,\n",
       "   0.9375,\n",
       "   0.8125,\n",
       "   0.65625,\n",
       "   0.71875,\n",
       "   0.9375,\n",
       "   0.5625,\n",
       "   0.96875]}}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3584f147",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array(test_df.select(feature_columns).collect())\n",
    "y = np.array(test_df.select(label_columns).collect())\n",
    "x = [x[:,i,np.newaxis] for i in range(x.shape[1])]\n",
    "y = np.squeeze(y,1)\n",
    "\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79e17319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2516 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-22 06:48:47.947852: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.25163865089416504, 1.0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras_model = model.get_best_model().getModel()\n",
    "keras_model.evaluate(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d91c9158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Species_OHE': {'spark_data_type': pyspark.sql.types.BinaryType,\n",
       "  'is_sparse_vector_only': False,\n",
       "  'shape': None,\n",
       "  'intermediate_format': 'nochange',\n",
       "  'max_size': None},\n",
       " 'SepalLengthCm': {'spark_data_type': pyspark.sql.types.DoubleType,\n",
       "  'is_sparse_vector_only': False,\n",
       "  'shape': None,\n",
       "  'intermediate_format': 'nochange',\n",
       "  'max_size': None},\n",
       " 'SepalWidthCm': {'spark_data_type': pyspark.sql.types.DoubleType,\n",
       "  'is_sparse_vector_only': False,\n",
       "  'shape': None,\n",
       "  'intermediate_format': 'nochange',\n",
       "  'max_size': None},\n",
       " 'PetalLengthCm': {'spark_data_type': pyspark.sql.types.DoubleType,\n",
       "  'is_sparse_vector_only': False,\n",
       "  'shape': None,\n",
       "  'intermediate_format': 'nochange',\n",
       "  'max_size': None},\n",
       " 'PetalWidthCm': {'spark_data_type': pyspark.sql.types.DoubleType,\n",
       "  'is_sparse_vector_only': False,\n",
       "  'shape': None,\n",
       "  'intermediate_format': 'nochange',\n",
       "  'max_size': None}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_best_model()._get_metadata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5877744b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEREBRO => Time: 2021-11-22 06:48:48, Running 1 Workers\n",
      "CEREBRO => Time: 2021-11-22 06:48:48, Num Partitions: 1\n",
      "CEREBRO => Time: 2021-11-22 06:48:48, Writing DataFrames\n",
      "CEREBRO => Time: 2021-11-22 06:48:48, Train Data Path: file:///Users/zijian/Desktop/ucsd/cse234/project/cerebro-system/experiments/intermediate_train_data\n",
      "CEREBRO => Time: 2021-11-22 06:48:48, Val Data Path: file:///Users/zijian/Desktop/ucsd/cse234/project/cerebro-system/experiments/intermediate_val_data\n",
      "CEREBRO => Time: 2021-11-22 06:48:49, Train Partitions: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEREBRO => Time: 2021-11-22 06:48:52, Val Partitions: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEREBRO => Time: 2021-11-22 06:48:54, Train Rows: 94\n",
      "CEREBRO => Time: 2021-11-22 06:48:54, Val Rows: 23\n"
     ]
    }
   ],
   "source": [
    "from cerebro.backend import SparkBackend\n",
    "from cerebro.keras import SparkEstimator\n",
    "\n",
    "# datas storage for intermediate data and model artifacts.\n",
    "from cerebro.storage import LocalStore, HDFSStore\n",
    "\n",
    "# Model selection/AutoML methods.\n",
    "from cerebro.tune import GridSearch, RandomSearch, TPESearch\n",
    "\n",
    "# Utility functions for specifying the search space.\n",
    "from cerebro.tune import hp_choice, hp_uniform, hp_quniform, hp_loguniform, hp_qloguniform\n",
    "\n",
    "import tensorflow as tf\n",
    "# tf.config.run_functions_eagerly(True)\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Cerebro Iris\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "...\n",
    "\n",
    "backend = SparkBackend(spark_context=spark.sparkContext, num_workers=1)\n",
    "store = LocalStore(prefix_path='/Users/zijian/Desktop/ucsd/cse234/project/cerebro-system/experiments')\n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "\n",
    "df = spark.read.csv(\"/Users/zijian/Desktop/ucsd/cse234/project/cerebro-system/Iris_clean.csv\", header=True, inferSchema=True)\n",
    "\n",
    "encoder = OneHotEncoderEstimator(dropLast=False)\n",
    "encoder.setInputCols([\"Species\"])\n",
    "encoder.setOutputCols([\"Species_OHE\"])\n",
    "\n",
    "encoder_model = encoder.fit(df)\n",
    "encoded = encoder_model.transform(df)\n",
    "\n",
    "feature_columns=['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n",
    "label_columns=['Species_OHE']\n",
    "\n",
    "# Initialize input DataFrames.\n",
    "# You can download sample dataset from https://apache.googlesource.com/spark/+/master/data/mllib/sample_libsvm_data.txt\n",
    "\n",
    "train_df, test_df = encoded.randomSplit([0.8, 0.2])\n",
    "\n",
    "# Define estimator generating function.\n",
    "# Input: Dictionary containing parameter values\n",
    "# Output: SparkEstimator\n",
    "def estimator_gen_fn(params):\n",
    "    inputs = [tf.keras.Input(shape=(1,)) for col in feature_columns]\n",
    "    embeddings = [tf.keras.layers.Dense(16, activation=tf.nn.relu)(input) for input in inputs]\n",
    "    combined = tf.keras.layers.Concatenate()(embeddings)\n",
    "    output = tf.keras.layers.Dense(3, activation=tf.nn.softmax)(combined)\n",
    "    model = tf.keras.Model(inputs, output)\n",
    "\n",
    "#     inputs = tf.keras.Input(shape=(4,))\n",
    "#     output1 = tf.keras.layers.Dense(16, activation=tf.nn.relu)(inputs)\n",
    "#     output2 = tf.keras.layers.Dense(32, activation=tf.nn.relu)(output1)\n",
    "#     output = tf.keras.layers.Dense(3, activation=tf.nn.softmax)(output2)\n",
    "#     model = tf.keras.Model(inputs, output)\n",
    "\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=params['lr'])\n",
    "    loss = 'categorical_crossentropy'\n",
    "\n",
    "    estimator = SparkEstimator(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        loss=loss,\n",
    "        metrics=['accuracy'],\n",
    "        batch_size=params['batch_size'])\n",
    "\n",
    "    return estimator\n",
    "\n",
    "# Define dictionary containing the parameter search space.\n",
    "search_space = {\n",
    "    'lr': hp_choice([0.01, 0.001, 0.0001]),\n",
    "    'batch_size': hp_quniform(16, 64, 16)\n",
    "}\n",
    "\n",
    "# Instantiate TPE (Tree of Parzan Estimators a.k.a., HyperOpt) model selection object.\n",
    "model_selection = TPESearch(\n",
    "    backend=backend, \n",
    "    store=store, \n",
    "    estimator_gen_fn=estimator_gen_fn, \n",
    "    search_space=search_space,\n",
    "    num_models=1, \n",
    "    num_epochs=10, \n",
    "    validation=0.25, \n",
    "    evaluation_metric='loss',\n",
    "    feature_columns=feature_columns,\n",
    "    label_columns=label_columns\n",
    ")\n",
    "\n",
    "_, _, metadata, _ = model_selection.backend.prepare_data(model_selection.store, train_df, model_selection.validation, label_columns=model_selection.label_cols, feature_columns=model_selection.feature_cols)\n",
    "\n",
    "model_selection.backend.initialize_workers()\n",
    "\n",
    "model_selection.backend.initialize_data_loaders(model_selection.store, None, model_selection.feature_cols + model_selection.label_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93717841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Species_OHE': {'spark_data_type': pyspark.sql.types.BinaryType,\n",
       "  'is_sparse_vector_only': False,\n",
       "  'shape': None,\n",
       "  'intermediate_format': 'nochange',\n",
       "  'max_size': None},\n",
       " 'SepalLengthCm': {'spark_data_type': pyspark.sql.types.DoubleType,\n",
       "  'is_sparse_vector_only': False,\n",
       "  'shape': None,\n",
       "  'intermediate_format': 'nochange',\n",
       "  'max_size': None},\n",
       " 'SepalWidthCm': {'spark_data_type': pyspark.sql.types.DoubleType,\n",
       "  'is_sparse_vector_only': False,\n",
       "  'shape': None,\n",
       "  'intermediate_format': 'nochange',\n",
       "  'max_size': None},\n",
       " 'PetalLengthCm': {'spark_data_type': pyspark.sql.types.DoubleType,\n",
       "  'is_sparse_vector_only': False,\n",
       "  'shape': None,\n",
       "  'intermediate_format': 'nochange',\n",
       "  'max_size': None},\n",
       " 'PetalWidthCm': {'spark_data_type': pyspark.sql.types.DoubleType,\n",
       "  'is_sparse_vector_only': False,\n",
       "  'shape': None,\n",
       "  'intermediate_format': 'nochange',\n",
       "  'max_size': None}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0058e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SepalLengthCm': {'spark_data_type': pyspark.sql.types.DoubleType,\n",
       "  'is_sparse_vector_only': False,\n",
       "  'shape': 1,\n",
       "  'intermediate_format': 'nochange',\n",
       "  'max_size': 1},\n",
       " 'SepalWidthCm': {'spark_data_type': pyspark.sql.types.DoubleType,\n",
       "  'is_sparse_vector_only': False,\n",
       "  'shape': 1,\n",
       "  'intermediate_format': 'nochange',\n",
       "  'max_size': 1},\n",
       " 'PetalLengthCm': {'spark_data_type': pyspark.sql.types.DoubleType,\n",
       "  'is_sparse_vector_only': False,\n",
       "  'shape': 1,\n",
       "  'intermediate_format': 'nochange',\n",
       "  'max_size': 1},\n",
       " 'PetalWidthCm': {'spark_data_type': pyspark.sql.types.DoubleType,\n",
       "  'is_sparse_vector_only': False,\n",
       "  'shape': 1,\n",
       "  'intermediate_format': 'nochange',\n",
       "  'max_size': 1},\n",
       " 'Species': {'spark_data_type': pyspark.sql.types.IntegerType,\n",
       "  'is_sparse_vector_only': False,\n",
       "  'shape': 1,\n",
       "  'intermediate_format': 'nochange',\n",
       "  'max_size': 1},\n",
       " 'Species_OHE': {'spark_data_type': pyspark.ml.linalg.SparseVector,\n",
       "  'is_sparse_vector_only': True,\n",
       "  'shape': 3,\n",
       "  'intermediate_format': 'custom_sparse_format',\n",
       "  'max_size': 1}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cerebro.backend.spark.util import _get_metadata\n",
    "\n",
    "_get_metadata(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1fe087f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.0>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.2>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.6>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.6>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.1>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.1>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.3>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.0>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.2>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.2>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.8>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.0>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.3>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.2>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.4>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.0>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.3>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.2>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.5>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.5>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.3>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.3>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.5>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.3>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.3>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.4>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.4>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.9>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.4>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.1>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.8>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.0>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.4>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.2>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.4>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.9>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.4>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.2>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.6>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.2>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.4>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.2>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.9>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.0>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.4>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.2>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.0>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.3>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.4>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.2>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.0>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.6>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.4>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.2>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.5>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.2>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.4>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.3>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.8>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.0>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.4>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.3>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.1>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.5>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.5>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.1>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.9>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.1>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.5>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.1>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.9>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.1>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.5>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.1>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.2>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.1>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.5>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.2>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.2>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.5>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.5>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.2>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.4>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.7>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.5>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.3>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.1>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.8>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.5>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.4>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.7>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.4>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.6>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.2>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.7>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.2>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.6>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.2>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.8>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.4>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.6>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.2>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.0>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.0>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.6>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.2>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.1>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.8>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.7>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.2>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.4>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.4>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.7>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.3>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.7>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.8>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.7>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.4>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.4>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.9>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.7>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.5>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.1>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.3>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.9>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=0.4>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.1>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.8>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([1., 0., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.3>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.0>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.0>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.3>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.5>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.0>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.7>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.6>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.8>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.1>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.5>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.4>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.9>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.1>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.6>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.5>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.9>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.2>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.8>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.7>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.0>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.0>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.0>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.2>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.0>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.3>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.5>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.3>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.0>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.3>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.5>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.5>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.0>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.3>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.1>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.8>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.1>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.3>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.6>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.0>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.1>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.3>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.7>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.8>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.2>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.2>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.7>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.0>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.2>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.3>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.6>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.7>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.2>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.3>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.7>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.9>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.2>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.5>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.9>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.0>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.3>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.3>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.4>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.9>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.4>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.2>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.5>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.6>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.4>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.3>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.3>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.3>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.4>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.4>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.6>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.0>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.5>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.3>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.7>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.8>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.5>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.5>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.4>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.0>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.5>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.5>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.0>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.9>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.5>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.5>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.4>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.2>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.5>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.6>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.0>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.4>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.5>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.7>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.9>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.5>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 0., 1.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.6>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.3>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.6>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.9>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.6>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.4>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.1>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.0>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.7>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.2>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.1>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.8>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.7>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.4>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.1>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.9>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.7>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.4>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=7.0>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.2>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.7>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.5>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.7>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.1>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.7>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.6>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.3>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.3>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.8>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.4>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.8>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.8>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.8>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.8>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.9>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.2>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.8>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.8>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.2>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.8>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 0., 1.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.9>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.5>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.3>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.5>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=4.9>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.8>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.3>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.7>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 0., 1.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.0>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.9>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.3>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.5>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 0., 1.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.0>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.0>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.7>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.5>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 0., 1.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.1>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.6>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.0>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.7>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 1., 0.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.1>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.8>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.9>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.0>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 0., 1.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.1>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.9>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.8>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.7>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 0., 1.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.1>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.0>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.5>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.2>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 0., 1.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.1>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.3>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.9>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.1>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 0., 1.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.2>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.0>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.5>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.0>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 0., 1.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.2>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.3>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.7>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.0>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 0., 1.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.3>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.3>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.4>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.2>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 0., 1.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.4>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.1>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.9>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.1>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 0., 1.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.6>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.8>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.3>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.9>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 0., 1.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.6>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.4>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.3>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.4>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 0., 1.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.7>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.3>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.9>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.2>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 0., 1.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.7>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.5>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.7>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.3>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 0., 1.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.8>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.6>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=7.2>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.0>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 0., 1.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.8>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.2>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.5>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.0>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 0., 1.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=5.9>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.1>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=7.1>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.0>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 0., 1.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.0>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.8>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=7.2>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.2>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 0., 1.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.1>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.9>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=7.4>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.8>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 0., 1.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.1>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.3>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=7.7>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.0>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 0., 1.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.3>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=1.8>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=7.3>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.9>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 0., 1.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.4>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.0>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=7.9>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.8>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 0., 1.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.6>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.1>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=7.6>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=3.0>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 0., 1.])>)\n",
      "petastorm_schema_view(PetalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=6.7>, PetalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.0>, SepalLengthCm=<tf.Tensor: shape=(), dtype=float64, numpy=7.7>, SepalWidthCm=<tf.Tensor: shape=(), dtype=float64, numpy=2.8>, Species_OHE=<tf.Tensor: shape=(3,), dtype=float64, numpy=array([0., 0., 1.])>)\n"
     ]
    }
   ],
   "source": [
    "from petastorm import make_reader\n",
    "\n",
    "from petastorm.tf_utils import make_petastorm_dataset\n",
    "\n",
    "with make_reader('file:///Users/zijian/Desktop/ucsd/cse234/project/cerebro-system/experiments/intermediate_train_data') as reader:\n",
    "    dataset = make_petastorm_dataset(reader)\n",
    "    for ele in dataset:\n",
    "        print(ele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d45d9be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(SepalLengthCm=4.3, SepalWidthCm=3.0, PetalLengthCm=1.1, PetalWidthCm=0.1, Species=0, Species_OHE=SparseVector(3, {0: 1.0})),\n",
       " Row(SepalLengthCm=4.4, SepalWidthCm=2.9, PetalLengthCm=1.4, PetalWidthCm=0.2, Species=0, Species_OHE=SparseVector(3, {0: 1.0})),\n",
       " Row(SepalLengthCm=4.4, SepalWidthCm=3.0, PetalLengthCm=1.3, PetalWidthCm=0.2, Species=0, Species_OHE=SparseVector(3, {0: 1.0})),\n",
       " Row(SepalLengthCm=4.4, SepalWidthCm=3.2, PetalLengthCm=1.3, PetalWidthCm=0.2, Species=0, Species_OHE=SparseVector(3, {0: 1.0})),\n",
       " Row(SepalLengthCm=4.5, SepalWidthCm=2.3, PetalLengthCm=1.3, PetalWidthCm=0.3, Species=0, Species_OHE=SparseVector(3, {0: 1.0})),\n",
       " Row(SepalLengthCm=4.6, SepalWidthCm=3.2, PetalLengthCm=1.4, PetalWidthCm=0.2, Species=0, Species_OHE=SparseVector(3, {0: 1.0})),\n",
       " Row(SepalLengthCm=4.6, SepalWidthCm=3.6, PetalLengthCm=1.0, PetalWidthCm=0.2, Species=0, Species_OHE=SparseVector(3, {0: 1.0})),\n",
       " Row(SepalLengthCm=4.7, SepalWidthCm=3.2, PetalLengthCm=1.6, PetalWidthCm=0.2, Species=0, Species_OHE=SparseVector(3, {0: 1.0})),\n",
       " Row(SepalLengthCm=4.8, SepalWidthCm=3.0, PetalLengthCm=1.4, PetalWidthCm=0.1, Species=0, Species_OHE=SparseVector(3, {0: 1.0})),\n",
       " Row(SepalLengthCm=4.8, SepalWidthCm=3.0, PetalLengthCm=1.4, PetalWidthCm=0.3, Species=0, Species_OHE=SparseVector(3, {0: 1.0}))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 25:>                                                         (0 + 1) / 1]"
     ]
    }
   ],
   "source": [
    "train_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cb1b9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
