{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "023ecc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.datasets import load_files\n",
    "\n",
    "import autokeras as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a327dcd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000,)\n",
      "b'Zero Day leads you to think, even re-think why two'\n"
     ]
    }
   ],
   "source": [
    "dataset = tf.keras.utils.get_file(\n",
    "    fname=\"aclImdb.tar.gz\",\n",
    "    origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n",
    "    extract=True,\n",
    ")\n",
    "\n",
    "# set path to dataset\n",
    "IMDB_DATADIR = os.path.join(os.path.dirname(dataset), \"aclImdb\")\n",
    "\n",
    "classes = [\"pos\", \"neg\"]\n",
    "train_data = load_files(\n",
    "    os.path.join(IMDB_DATADIR, \"train\"), shuffle=True, categories=classes\n",
    ")\n",
    "test_data = load_files(\n",
    "    os.path.join(IMDB_DATADIR, \"test\"), shuffle=False, categories=classes\n",
    ")\n",
    "\n",
    "x_train = np.array(train_data.data)\n",
    "y_train = np.array(train_data.target)\n",
    "x_test = np.array(test_data.data)\n",
    "y_test = np.array(test_data.target)\n",
    "\n",
    "print(x_train.shape)  # (25000,)\n",
    "print(y_train.shape)  # (25000, 1)\n",
    "print(x_train[0][:50])  # this film was just brilliant casting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11835075",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/06 23:27:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEREBRO => Time: 2021-12-06 23:27:31, Running 1 Workers\n"
     ]
    }
   ],
   "source": [
    "from cerebro.backend import SparkBackend\n",
    "from cerebro.keras import SparkEstimator\n",
    "\n",
    "# datas storage for intermediate data and model artifacts.\n",
    "from cerebro.storage import LocalStore, HDFSStore\n",
    "\n",
    "# Model selection/AutoML methods.\n",
    "from cerebro.tune import GridSearch, RandomSearch, TPESearch\n",
    "\n",
    "# Utility functions for specifying the search space.\n",
    "from cerebro.tune import hp_choice, hp_uniform, hp_quniform, hp_loguniform, hp_qloguniform\n",
    "\n",
    "import tensorflow as tf\n",
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Cerebro Example\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "...\n",
    "work_dir = '/Users/zijian/Desktop/ucsd/cse234/project/cerebro-system/'\n",
    "backend = SparkBackend(spark_context=spark.sparkContext, num_workers=1)\n",
    "store = LocalStore(prefix_path=work_dir + 'test/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e9fe990",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = np.stack([x_train, y_train], axis=1)\n",
    "test_data = np.stack([x_test, y_test], axis=1)\n",
    "all_data = np.concatenate([train_data, test_data], axis=0)\n",
    "all_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1564747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b\"Zero Day leads you to think, even re-think why two boys/young men would do what they did - commit mutual suicide via slaughtering their classmates. It captures what must be beyond a bizarre mode of being for two humans who have decided to withdraw from common civility in order to define their own/mutual world via coupled destruction.<br /><br />It is not a perfect movie but given what money/time the filmmaker and actors had - it is a remarkable product. In terms of explaining the motives and actions of the two young suicide/murderers it is better than 'Elephant' - in terms of being a film that gets under our 'rationalistic' skin it is a far, far better film than almost anything you are likely to see. <br /><br />Flawed but honest with a terrible honesty.\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9133f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/06 22:08:52 WARN TaskSetManager: Stage 0 contains a task of very large size (5408 KB). The maximum recommended task size is 100 KB.\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------------+\n",
      "|            features|label|    label_OHE|\n",
      "+--------------------+-----+-------------+\n",
      "|Zero Day leads yo...|    1|(2,[1],[1.0])|\n",
      "|Words can't descr...|    0|(2,[0],[1.0])|\n",
      "|Everyone plays th...|    1|(2,[1],[1.0])|\n",
      "|There are a lot o...|    0|(2,[0],[1.0])|\n",
      "|I've just had the...|    0|(2,[0],[1.0])|\n",
      "+--------------------+-----+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/12/06 22:08:53 WARN TaskSetManager: Stage 2 contains a task of very large size (5408 KB). The maximum recommended task size is 100 KB.\n"
     ]
    }
   ],
   "source": [
    "dff = map(lambda x: (x[0].decode('UTF-8') ,int(x[1])), all_data)\n",
    "mydf = spark.createDataFrame(dff,schema=[\"features\", \"label\"])\n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "\n",
    "encoder = OneHotEncoderEstimator(dropLast=False)\n",
    "encoder.setInputCols([\"label\"])\n",
    "encoder.setOutputCols([\"label_OHE\"])\n",
    "\n",
    "encoder_model = encoder.fit(mydf)\n",
    "encoded = encoder_model.transform(mydf)\n",
    "\n",
    "feature_columns=['features']\n",
    "label_columns=['label_OHE']\n",
    "\n",
    "encoded.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "764bbaa5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "'CSV data source does not support struct<type:tinyint,size:int,indices:array<int>,values:array<double>> data type.;'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/envs/nocerebro/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/envs/nocerebro/lib/python3.7/site-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o86.save.\n: org.apache.spark.sql.AnalysisException: CSV data source does not support struct<type:tinyint,size:int,indices:array<int>,values:array<double>> data type.;\n\tat org.apache.spark.sql.execution.datasources.DataSourceUtils$$anonfun$verifySchema$1.apply(DataSourceUtils.scala:69)\n\tat org.apache.spark.sql.execution.datasources.DataSourceUtils$$anonfun$verifySchema$1.apply(DataSourceUtils.scala:67)\n\tat scala.collection.Iterator$class.foreach(Iterator.scala:891)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1334)\n\tat scala.collection.IterableLike$class.foreach(IterableLike.scala:72)\n\tat org.apache.spark.sql.types.StructType.foreach(StructType.scala:99)\n\tat org.apache.spark.sql.execution.datasources.DataSourceUtils$.verifySchema(DataSourceUtils.scala:67)\n\tat org.apache.spark.sql.execution.datasources.DataSourceUtils$.verifyWriteSchema(DataSourceUtils.scala:34)\n\tat org.apache.spark.sql.execution.datasources.FileFormatWriter$.write(FileFormatWriter.scala:100)\n\tat org.apache.spark.sql.execution.datasources.InsertIntoHadoopFsRelationCommand.run(InsertIntoHadoopFsRelationCommand.scala:159)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult$lzycompute(commands.scala:104)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.sideEffectResult(commands.scala:102)\n\tat org.apache.spark.sql.execution.command.DataWritingCommandExec.doExecute(commands.scala:122)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:131)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$execute$1.apply(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$executeQuery$1.apply(SparkPlan.scala:155)\n\tat org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:151)\n\tat org.apache.spark.sql.execution.SparkPlan.executeQuery(SparkPlan.scala:152)\n\tat org.apache.spark.sql.execution.SparkPlan.execute(SparkPlan.scala:127)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd$lzycompute(QueryExecution.scala:83)\n\tat org.apache.spark.sql.execution.QueryExecution.toRdd(QueryExecution.scala:81)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:676)\n\tat org.apache.spark.sql.DataFrameWriter$$anonfun$runCommand$1.apply(DataFrameWriter.scala:676)\n\tat org.apache.spark.sql.execution.SQLExecution$$anonfun$withNewExecutionId$1.apply(SQLExecution.scala:80)\n\tat org.apache.spark.sql.execution.SQLExecution$.withSQLConfPropagated(SQLExecution.scala:127)\n\tat org.apache.spark.sql.execution.SQLExecution$.withNewExecutionId(SQLExecution.scala:75)\n\tat org.apache.spark.sql.DataFrameWriter.runCommand(DataFrameWriter.scala:676)\n\tat org.apache.spark.sql.DataFrameWriter.saveToV1Source(DataFrameWriter.scala:285)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:271)\n\tat org.apache.spark.sql.DataFrameWriter.save(DataFrameWriter.scala:229)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dg/4jghvsmd1dl77gj1fqmzzf_80000gn/T/ipykernel_11528/3862604786.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"imdb.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/envs/nocerebro/lib/python3.7/site-packages/pyspark/sql/readwriter.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, path, format, mode, partitionBy, **options)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jwrite\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0msince\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1.4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/envs/nocerebro/lib/python3.7/site-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.7.6/envs/nocerebro/lib/python3.7/site-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: 'CSV data source does not support struct<type:tinyint,size:int,indices:array<int>,values:array<double>> data type.;'"
     ]
    }
   ],
   "source": [
    "encoded.write.save(\"imdb.csv\", format=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cad36774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+\n",
      "|            features|    label_OHE|\n",
      "+--------------------+-------------+\n",
      "|Lauren Himmel's d...|(2,[1],[1.0])|\n",
      "|The Pickle was th...|(2,[1],[1.0])|\n",
      "|This is a great o...|(2,[1],[1.0])|\n",
      "|I liked this show...|(2,[1],[1.0])|\n",
      "|I have watched Fa...|(2,[1],[1.0])|\n",
      "+--------------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "feature_columns=['features']\n",
    "label_columns=['label_OHE']\n",
    "df = spark.read.load(\"imdb.parquet\")\n",
    "df = df.select(feature_columns+label_columns)\n",
    "df.show(5)\n",
    "train_df, test_df = df.randomSplit([0.8, 0.2], seed=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "084c3e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_tuner.engine import hyperparameters\n",
    "import autokeras as ak\n",
    "from cerebro.nas.hphpmodel import HyperHyperModel\n",
    "\n",
    "input_node = ak.TextInput()\n",
    "output_node = ak.TextBlock(block_type=\"ngram\")(input_node)\n",
    "output_node = ak.ClassificationHead(num_classes=2, multi_label=True)(output_node)\n",
    "am = HyperHyperModel(input_node, output_node, seed=2000)\n",
    "\n",
    "am.resource_bind(\n",
    "    backend=backend, \n",
    "    store=store,\n",
    "    feature_columns=feature_columns,\n",
    "    label_columns=label_columns,\n",
    "    evaluation_metric='accuracy', \n",
    ")\n",
    "\n",
    "am.tuner_bind(\n",
    "    tuner=\"greedy\", \n",
    "#     tuner=\"randomsearch\",\n",
    "    hyperparameters=None, \n",
    "    objective=\"val_accuracy\",\n",
    "    max_trials=2,\n",
    "    overwrite=True,\n",
    "    exploration=0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3a1a9a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEREBRO => Time: 2021-12-06 23:27:34, Preparing Data\n",
      "CEREBRO => Time: 2021-12-06 23:27:34, Num Partitions: 12\n",
      "CEREBRO => Time: 2021-12-06 23:27:34, Writing DataFrames\n",
      "CEREBRO => Time: 2021-12-06 23:27:34, Train Data Path: file:///Users/zijian/Desktop/ucsd/cse234/project/cerebro-system/test/intermediate_train_data\n",
      "CEREBRO => Time: 2021-12-06 23:27:34, Val Data Path: file:///Users/zijian/Desktop/ucsd/cse234/project/cerebro-system/test/intermediate_val_data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEREBRO => Time: 2021-12-06 23:27:37, Train Partitions: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEREBRO => Time: 2021-12-06 23:27:45, Val Partitions: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CEREBRO => Time: 2021-12-06 23:27:58, Train Rows: 31940\n",
      "CEREBRO => Time: 2021-12-06 23:27:58, Val Rows: 8030\n",
      "CEREBRO => Time: 2021-12-06 23:27:58, Initializing Workers\n",
      "CEREBRO => Time: 2021-12-06 23:27:58, Initializing Data Loaders\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-06 23:28:08.160734: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2021-12-06 23:28:08.161511: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "text_block_1/ma...|5000              |?                 \n",
      "text_block_1/te...|2                 |?                 \n",
      "text_block_1/de...|True              |?                 \n",
      "text_block_1/de...|1                 |?                 \n",
      "text_block_1/de...|256               |?                 \n",
      "text_block_1/de...|0.25              |?                 \n",
      "text_block_1/de...|256               |?                 \n",
      "classification_...|0                 |?                 \n",
      "optimizer         |adam              |?                 \n",
      "learning_rate     |0.001             |?                 \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9:>                                                          (0 + 1) / 1]2021-12-06 23:28:08.735726: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/dg/4jghvsmd1dl77gj1fqmzzf_80000gn/T/ipykernel_14413/3922750888.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/ucsd/cse234/project/cerebro-system/cerebro/nas/hphpmodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, df, batch_size, epochs, callbacks, verbose, input_shape, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mdataset_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m         )\n\u001b[1;32m    289\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ucsd/cse234/project/cerebro-system/cerebro/nas/tuners/greedy.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, epochs, callbacks, validation_split, verbose, dataset_idx, metadata, cold_start, **fit_kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0mtrials\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrunning_trials\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbegin_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_trials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/ucsd/cse234/project/cerebro-system/cerebro/nas/tuners/greedy.py\u001b[0m in \u001b[0;36mrun_trials\u001b[0;34m(self, trials, epochs, dataset_idx, metadata, **fit_kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0mest_results_log\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetRunId\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimators\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 333\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    334\u001b[0m             \u001b[0mtrain_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_for_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    335\u001b[0m             \u001b[0mupdate_model_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mest_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object cannot be interpreted as an integer"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 1) / 1]"
     ]
    }
   ],
   "source": [
    "am.fit(train_df,epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c855e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from cerebro.backend.spark.util import _get_metadata\n",
    "\n",
    "unischema_fields = []\n",
    "metadata = _get_metadata(train_df)\n",
    "for k in metadata.keys():\n",
    "    type = spark_to_petastorm_type(metadata[k]['spark_data_type'])\n",
    "    shape = petastorm_unischema_shape(metadata[k]['shape'])\n",
    "    codec = petastorm_unischema_codec(metadata[k]['shape'], metadata[k]['spark_data_type'])\n",
    "    unischema_fields.append(UnischemaField(k, type, shape, codec, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccb90f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[UnischemaField(name='features', numpy_dtype=<class 'numpy.uint8'>, shape=(), codec=<petastorm.codecs.ScalarCodec object at 0x17b1d1190>, nullable=False),\n",
       " UnischemaField(name='label', numpy_dtype=<class 'numpy.int64'>, shape=(), codec=<petastorm.codecs.ScalarCodec object at 0x17b1d11d0>, nullable=False),\n",
       " UnischemaField(name='label_OHE', numpy_dtype=<class 'numpy.float64'>, shape=(2,), codec=<petastorm.codecs.NdarrayCodec object at 0x17b1d10d0>, nullable=False)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unischema_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a67c7a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features': {'spark_data_type': pyspark.sql.types.StringType,\n",
       "  'is_sparse_vector_only': False,\n",
       "  'shape': 1,\n",
       "  'intermediate_format': 'nochange',\n",
       "  'max_size': 1},\n",
       " 'label': {'spark_data_type': pyspark.sql.types.LongType,\n",
       "  'is_sparse_vector_only': False,\n",
       "  'shape': 1,\n",
       "  'intermediate_format': 'nochange',\n",
       "  'max_size': 1},\n",
       " 'label_OHE': {'spark_data_type': pyspark.ml.linalg.SparseVector,\n",
       "  'is_sparse_vector_only': True,\n",
       "  'shape': 2,\n",
       "  'intermediate_format': 'custom_sparse_format',\n",
       "  'max_size': 1}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1691862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unischema(petastorm_schema, [\n",
      "  UnischemaField('features', uint8, (), <petastorm.codecs.ScalarCodec object at 0x17b1d1190>, False),\n",
      "  UnischemaField('label', int64, (), <petastorm.codecs.ScalarCodec object at 0x17b1d11d0>, False),\n",
      "  UnischemaField('label_OHE', float64, (2,), <petastorm.codecs.NdarrayCodec object at 0x17b1d10d0>, False),\n",
      "])\n"
     ]
    }
   ],
   "source": [
    "from petastorm.unischema import Unischema, UnischemaField, dict_to_spark_row\n",
    "petastorm_schema = Unischema('petastorm_schema', unischema_fields)\n",
    "print(petastorm_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0092e130",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'features': '\"... the beat is too strong ... we\\'re deaf mutants now--like them\", Rex Voorhas Ormine<br /><br />I am surprised that this movie has been uniformly bashed. Let me be the first to actually discuss the virtues of \"The Beat\" and why YOU MUST SEE THIS FILM NOW.<br /><br />Make no mistake, this movie is cheesy and \"bad\" in the conventional sense: the story is preposterous, the poetry is silly, and the acting is inconsistent.<br /><br />But these are the film\\'s CHARMS--all of these ingredients form the recipe for one of the most UNDERAPPRECIATED CHEEZY FILMS of the 80\\'s.<br /><br />If the reference to \"deaf mutants\" didn\\'t pique your interest, then perhaps this will: What kind of name is \"Rex Voorhas Ormine\", anyway? It is such an unusual name (for North American audiences) that I said to myself, \"even the names of the characters in this friggin\\' movie are firggin\\' silly.\"<br /><br />Well, \"The Beat\" is so fabulously cheezy that the \"meaning\" and \"symbolism\" behind \"Rex Voorhas Ormine\" is revealed not-too-subtly by Bart Waxman (the misguided guidance counselor you love to hate). I won\\'t spoil the revelation behind Rex\\'s name, but please don\\'t get too excited, O.K.?<br /><br />Overall, the acting is inconsistent (John Savage--who plays the \"concerned teacher\" Mr. Ellsworth is pretty good, as is the fellow playing Bart Waxman, but the rest of the cast are unconvincing). That said, the acting does NOT detract from the film. Why? There is a SINCERITY in each of the actors\\' performances that makes the characters they play endearing. So although the performances may suck, you are still left with the impression that the actors are really trying to do their best. As a result, the actors\\' sincerity succeeds where their acting fails (which is quite often).<br /><br />The homage to \"beat poetry\" in this film is bad, bad, bad. But this is a good, good, good thing when it comes to entertainment. Would you actually enjoy \"better quality\" or \"more respectable\" poetry--especially in a film like this?<br /><br />Folks, that would be BORING (think about the droll they made us read in high school--sanitized to avoid \"corrupting the youth\", politically conservative and devoid of any critical analysis, etc.) Even if you don\\'t like poetry or \"arty\" movies (with all of the \"intellectual\" posturing that implies), you most certainly can (and should) appreciate LUDICROUS POETRY in a WANNABE ART FILM!!!! How could you not enjoy the following?<br /><br />\"do you remember the roar of the dinosaur? a woman\\'s scotty craps on the floor bad scotty bad, oh the woman\\'s so sad she washes her hands and then waits by the door today, yeah--today!\"<br /><br />Yes, that is an example of some of the remarkable poetry liberally sprinkled throughout \"The Beat.\" But what about the story, you ask?<br /><br />Well, the story is preposterous. But then again, that is the beauty of this film. Apart from some cliches, stereotypes, and predictable plot points, there are enough genuinely unique elements to the plot/story to keep things interesting. Who is Rex? Where did he come from? What the heck is he talking about? Deaf mutants? Illiterate angels? Do Billy and Kate REALLY understand what Rex is saying? Is the audience supposed to understand Rex and his poetry posse? (I\\'ve seen the movie several times and I still haven\\'t figured everything out.)<br /><br />Will bad poetry and high school talent shows really END GANG VIOLENCE?<br /><br />I guarantee that you have never seen anything quite like \"The Beat\"--a perfect combination of brilliantly bad poetry, mediocre-yet-sincere acting, and a \"mythopoetics conquers gang violence\" storyline that has YET TO BE RIVALLED BY ANY FILM EVER MADE.<br /><br />Bonus for fans of classic NYC hardcore: The Cro-Mags make a rare film appearance as the \"Iron Skulls\" and it\\'s a hoot to see them perform several songs. I wish they included more concert footage, but maybe that will be an \"extra\" included on the \"collector\\'s edition\" DVD I fantasize about.<br /><br />', 'label': 1, 'label_OHE': SparseVector(2, {1: 1.0})}]\n"
     ]
    }
   ],
   "source": [
    "print(train_df.rdd \\\n",
    "  .map(lambda x: x.asDict()) \\\n",
    "  .take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a803f89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 8:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'features': array([34, 46, 46, ..., 32, 47, 62], dtype=uint8), 'label': array(1), 'label_OHE': array([0., 1.])}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(train_df.rdd \\\n",
    "      .map(lambda x: x.asDict()) \\\n",
    "      .map(lambda x: {k: create_array(x,k,spark_to_petastorm_type(metadata[k]['spark_data_type'])) for k in x}) \\\n",
    "      .take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "84e1ca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_to_np(x,k,dtype):\n",
    "    if dtype == np.uint8:\n",
    "        return x[k]\n",
    "    else:\n",
    "        return np.array(x[k], dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1062862",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 9:>                                                          (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'features': '\"... the beat is too strong ... we\\'re deaf mutants now--like them\", Rex Voorhas Ormine<br /><br />I am surprised that this movie has been uniformly bashed. Let me be the first to actually discuss the virtues of \"The Beat\" and why YOU MUST SEE THIS FILM NOW.<br /><br />Make no mistake, this movie is cheesy and \"bad\" in the conventional sense: the story is preposterous, the poetry is silly, and the acting is inconsistent.<br /><br />But these are the film\\'s CHARMS--all of these ingredients form the recipe for one of the most UNDERAPPRECIATED CHEEZY FILMS of the 80\\'s.<br /><br />If the reference to \"deaf mutants\" didn\\'t pique your interest, then perhaps this will: What kind of name is \"Rex Voorhas Ormine\", anyway? It is such an unusual name (for North American audiences) that I said to myself, \"even the names of the characters in this friggin\\' movie are firggin\\' silly.\"<br /><br />Well, \"The Beat\" is so fabulously cheezy that the \"meaning\" and \"symbolism\" behind \"Rex Voorhas Ormine\" is revealed not-too-subtly by Bart Waxman (the misguided guidance counselor you love to hate). I won\\'t spoil the revelation behind Rex\\'s name, but please don\\'t get too excited, O.K.?<br /><br />Overall, the acting is inconsistent (John Savage--who plays the \"concerned teacher\" Mr. Ellsworth is pretty good, as is the fellow playing Bart Waxman, but the rest of the cast are unconvincing). That said, the acting does NOT detract from the film. Why? There is a SINCERITY in each of the actors\\' performances that makes the characters they play endearing. So although the performances may suck, you are still left with the impression that the actors are really trying to do their best. As a result, the actors\\' sincerity succeeds where their acting fails (which is quite often).<br /><br />The homage to \"beat poetry\" in this film is bad, bad, bad. But this is a good, good, good thing when it comes to entertainment. Would you actually enjoy \"better quality\" or \"more respectable\" poetry--especially in a film like this?<br /><br />Folks, that would be BORING (think about the droll they made us read in high school--sanitized to avoid \"corrupting the youth\", politically conservative and devoid of any critical analysis, etc.) Even if you don\\'t like poetry or \"arty\" movies (with all of the \"intellectual\" posturing that implies), you most certainly can (and should) appreciate LUDICROUS POETRY in a WANNABE ART FILM!!!! How could you not enjoy the following?<br /><br />\"do you remember the roar of the dinosaur? a woman\\'s scotty craps on the floor bad scotty bad, oh the woman\\'s so sad she washes her hands and then waits by the door today, yeah--today!\"<br /><br />Yes, that is an example of some of the remarkable poetry liberally sprinkled throughout \"The Beat.\" But what about the story, you ask?<br /><br />Well, the story is preposterous. But then again, that is the beauty of this film. Apart from some cliches, stereotypes, and predictable plot points, there are enough genuinely unique elements to the plot/story to keep things interesting. Who is Rex? Where did he come from? What the heck is he talking about? Deaf mutants? Illiterate angels? Do Billy and Kate REALLY understand what Rex is saying? Is the audience supposed to understand Rex and his poetry posse? (I\\'ve seen the movie several times and I still haven\\'t figured everything out.)<br /><br />Will bad poetry and high school talent shows really END GANG VIOLENCE?<br /><br />I guarantee that you have never seen anything quite like \"The Beat\"--a perfect combination of brilliantly bad poetry, mediocre-yet-sincere acting, and a \"mythopoetics conquers gang violence\" storyline that has YET TO BE RIVALLED BY ANY FILM EVER MADE.<br /><br />Bonus for fans of classic NYC hardcore: The Cro-Mags make a rare film appearance as the \"Iron Skulls\" and it\\'s a hoot to see them perform several songs. I wish they included more concert footage, but maybe that will be an \"extra\" included on the \"collector\\'s edition\" DVD I fantasize about.<br /><br />', 'label': array(1), 'label_OHE': array([0., 1.])}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(train_df.rdd \\\n",
    "      .map(lambda x: x.asDict()) \\\n",
    "      .map(lambda x: {k: map_to_np(x,k,spark_to_petastorm_type(metadata[k]['spark_data_type'])) for k in x}) \\\n",
    "      .take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b7eae4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 11:>                                                         (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Row(features='\"... the beat is too strong ... we\\'re deaf mutants now--like them\", Rex Voorhas Ormine<br /><br />I am surprised that this movie has been uniformly bashed. Let me be the first to actually discuss the virtues of \"The Beat\" and why YOU MUST SEE THIS FILM NOW.<br /><br />Make no mistake, this movie is cheesy and \"bad\" in the conventional sense: the story is preposterous, the poetry is silly, and the acting is inconsistent.<br /><br />But these are the film\\'s CHARMS--all of these ingredients form the recipe for one of the most UNDERAPPRECIATED CHEEZY FILMS of the 80\\'s.<br /><br />If the reference to \"deaf mutants\" didn\\'t pique your interest, then perhaps this will: What kind of name is \"Rex Voorhas Ormine\", anyway? It is such an unusual name (for North American audiences) that I said to myself, \"even the names of the characters in this friggin\\' movie are firggin\\' silly.\"<br /><br />Well, \"The Beat\" is so fabulously cheezy that the \"meaning\" and \"symbolism\" behind \"Rex Voorhas Ormine\" is revealed not-too-subtly by Bart Waxman (the misguided guidance counselor you love to hate). I won\\'t spoil the revelation behind Rex\\'s name, but please don\\'t get too excited, O.K.?<br /><br />Overall, the acting is inconsistent (John Savage--who plays the \"concerned teacher\" Mr. Ellsworth is pretty good, as is the fellow playing Bart Waxman, but the rest of the cast are unconvincing). That said, the acting does NOT detract from the film. Why? There is a SINCERITY in each of the actors\\' performances that makes the characters they play endearing. So although the performances may suck, you are still left with the impression that the actors are really trying to do their best. As a result, the actors\\' sincerity succeeds where their acting fails (which is quite often).<br /><br />The homage to \"beat poetry\" in this film is bad, bad, bad. But this is a good, good, good thing when it comes to entertainment. Would you actually enjoy \"better quality\" or \"more respectable\" poetry--especially in a film like this?<br /><br />Folks, that would be BORING (think about the droll they made us read in high school--sanitized to avoid \"corrupting the youth\", politically conservative and devoid of any critical analysis, etc.) Even if you don\\'t like poetry or \"arty\" movies (with all of the \"intellectual\" posturing that implies), you most certainly can (and should) appreciate LUDICROUS POETRY in a WANNABE ART FILM!!!! How could you not enjoy the following?<br /><br />\"do you remember the roar of the dinosaur? a woman\\'s scotty craps on the floor bad scotty bad, oh the woman\\'s so sad she washes her hands and then waits by the door today, yeah--today!\"<br /><br />Yes, that is an example of some of the remarkable poetry liberally sprinkled throughout \"The Beat.\" But what about the story, you ask?<br /><br />Well, the story is preposterous. But then again, that is the beauty of this film. Apart from some cliches, stereotypes, and predictable plot points, there are enough genuinely unique elements to the plot/story to keep things interesting. Who is Rex? Where did he come from? What the heck is he talking about? Deaf mutants? Illiterate angels? Do Billy and Kate REALLY understand what Rex is saying? Is the audience supposed to understand Rex and his poetry posse? (I\\'ve seen the movie several times and I still haven\\'t figured everything out.)<br /><br />Will bad poetry and high school talent shows really END GANG VIOLENCE?<br /><br />I guarantee that you have never seen anything quite like \"The Beat\"--a perfect combination of brilliantly bad poetry, mediocre-yet-sincere acting, and a \"mythopoetics conquers gang violence\" storyline that has YET TO BE RIVALLED BY ANY FILM EVER MADE.<br /><br />Bonus for fans of classic NYC hardcore: The Cro-Mags make a rare film appearance as the \"Iron Skulls\" and it\\'s a hoot to see them perform several songs. I wish they included more concert footage, but maybe that will be an \"extra\" included on the \"collector\\'s edition\" DVD I fantasize about.<br /><br />', label=1, label_OHE=bytearray(b\"\\x93NUMPY\\x01\\x00v\\x00{\\'descr\\': \\'<f8\\', \\'fortran_order\\': False, \\'shape\\': (2,), }                                                            \\n\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\xf0?\"))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(train_df.rdd \\\n",
    "      .map(lambda x: x.asDict()) \\\n",
    "      .map(lambda x: {k: map_to_np(x,k,spark_to_petastorm_type(metadata[k]['spark_data_type'])) for k in x}) \\\n",
    "      .map(lambda x: dict_to_spark_row(petastorm_schema, x))\n",
    "      .take(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6d56043",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cerebro.backend.spark import util\n",
    "_, _, meta, avg_row_size = util.get_simple_meta_from_parquet(store, feature_columns+label_columns, None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b080f4e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'features': {'spark_data_type': pyspark.sql.types.StringType,\n",
       "  'is_sparse_vector_only': False,\n",
       "  'shape': None,\n",
       "  'intermediate_format': 'nochange',\n",
       "  'max_size': None},\n",
       " 'label_OHE': {'spark_data_type': pyspark.sql.types.BinaryType,\n",
       "  'is_sparse_vector_only': False,\n",
       "  'shape': None,\n",
       "  'intermediate_format': 'nochange',\n",
       "  'max_size': None}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:>                                                          (0 + 1) / 1]"
     ]
    }
   ],
   "source": [
    "meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf9f095",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
